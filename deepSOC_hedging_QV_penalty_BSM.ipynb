{"cells":[{"cell_type":"markdown","source":["## Deep Hedging with Quadratic Variation Penalty\n","- Suppose that we are hedging a short position in a European Call option using cash and underlying stock\n","- The marked-to-market value of the hedge portfolio is given by\n","\\begin{equation}\n","    V_t = C_t+H_t^SS_t,\n","\\end{equation}\n","where $C_t$ is the stock price (negative for short position) and $H_t^S$ is the hedge ratio (number of shares to hold).\n","- This formulation of hedging tries to solve the following stochastic optimization problem,\n","\\begin{equation}\n","\\min_{\\text{strategies}}\\mathbb{E}\\left[-V_T+\\frac{\\lambda}{2}\\langle V,V\\rangle_T\\right],\n","\\end{equation}\n","where $\\langle V, V\\rangle_T$ is the quadratic variation up to time $T$.\n","- Considering the instantanuous changes, the objective can be written as,\n","\\begin{equation}\n","\\min_{\\text{strategies}}\\mathbb{E}\\left[-\\int_0^TdV_t+\\frac{\\lambda}{2}\\int_0^Td\\langle V, V\\rangle_t \\right],\n","\\end{equation}\n","where $dV_t = dC_t+H_t^SdS_t$.\n","\n","Using Ito Calculus we have and assuming Black-Scholes $dS_t=\\mu S_tdt+\\sigma S_tdW_t$, the objective takes the form,\n","\\begin{align}\n","\\min_{\\text{strategies}}\\mathbb{E}\\left[-\\int_0^T\\partial_tC_t+\\partial_SC_t\\mu S_t+\\frac{1}{2}\\partial_{SS}C_t\\sigma^2S^2+\\mu S_tH_t+\\right.\\\\\n","\\left[+\\frac{\\lambda}{2}\\left((\\partial_SC_t)^2\\sigma^2S_t^2+H_t^2\\sigma^2S_t^2+2H_t\\partial_SC_t\\sigma^2S_t^2\\right)\\right]&\n","\\end{align}\n","\n","- By treating the integrand as a formal quadratic expression $\\Phi(H_t)$, the optimal strategy is dervied as,\n","\\begin{equation}\n","  H_t^* = \\Delta_t^{\\text{BS}}-\\frac{1}{\\lambda}\\frac{\\mu}{ \\sigma^2}\\frac{1}{S_t}\n","\\end{equation}\n","- For approximating the optimal startategy, we use the following discretized objective,\n","\n","\\begin{equation}\n","\\min_{\\text{strategies}}\\left[\\frac{1}{N}\\sum_{i=1}^N-P\\&L_i+\\frac{\\lambda}{2}P\\&L_i^2\\right],\n","\\end{equation}\n","where\n","\\begin{equation}\n","P\\&L_i = V_{t_i}-V_{t_{i-1}} = (C_{t_i}-C_{t_{i-1}})+H_{t_{i-1}}(S_{t_i}-S_{t_{i-1}}).\n","\\end{equation}"],"metadata":{"id":"dX6h9iB4d_c7"},"id":"dX6h9iB4d_c7"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"UXjEbe6neBqS","outputId":"55ef50d3-0fd8-4682-cc7d-b8e17a3ce2e1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719269198003,"user_tz":420,"elapsed":1487,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"UXjEbe6neBqS","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.insert(0,'/content/drive/MyDrive/deepHedge_QV')"],"metadata":{"id":"C2-_aTblKXK1","executionInfo":{"status":"ok","timestamp":1719269198003,"user_tz":420,"elapsed":7,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"C2-_aTblKXK1","execution_count":2,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.stats as stats\n","import seaborn as sns\n"],"metadata":{"id":"bAL1KlJWHe-Z","executionInfo":{"status":"ok","timestamp":1719269201001,"user_tz":420,"elapsed":3003,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"bAL1KlJWHe-Z","execution_count":3,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import scipy.stats as stats\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from tqdm import tqdm\n"],"metadata":{"id":"yl0RTGQGriHB","executionInfo":{"status":"ok","timestamp":1719269207246,"user_tz":420,"elapsed":6251,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"yl0RTGQGriHB","execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","def calculate_stock_prices(S_0,mu,vol,W): #maybe use Euler for stock\n","    S = torch.zeros(size=(W.shape[0],W.shape[1]))\n","    t = torch.arange(W.shape[1])\n","    for i in range(S.shape[0]):\n","        S[i,:] = S_0*np.exp(vol*W[i,:]+(mu-vol**2 /2)*t)\n","    return S\n","\n","def calculate_d1(S, K, ir, vol, tau):\n","    x = np.log(S/K) + (ir + vol**2 / 2) * tau\n","    return x / (vol * np.sqrt(tau))\n","\n","def calculate_d2(S, K, ir, vol, tau):\n","    x = np.log(S/K) + (ir - vol**2 / 2) * tau\n","    return x / (vol * np.sqrt(tau))\n","\n","def calculate_deltas(S, K, ir, vol, T):\n","\n","    dt = T / (S.shape[1]-1)\n","\n","    # Convert to torch tensors\n","    K = torch.full_like(S, K)\n","    ir = torch.full_like(S, ir)\n","    vol = torch.full_like(S, vol)\n","\n","    T = torch.full_like(S, T)\n","    t = torch.zeros_like(S)\n","    for j in range(t.shape[1]): t[:, j] = j*dt\n","    tau = T - t\n","    deltas = torch.zeros_like(S)\n","\n","    # Calculate prices before expiry\n","    d1 = calculate_d1(S[:, :-1], K[:, :-1], ir[:, :-1], vol[:, :-1], tau[:, :-1])\n","    deltas[:, :-1] = torch.from_numpy(stats.norm.cdf(d1))\n","\n","    # Calculate prices at expiry\n","    deltas[:, -1] = torch.from_numpy(np.where(S[:, -1] > K[:, -1], 1.0, 0.0))\n","\n","    return deltas"],"metadata":{"id":"J1dyFBfMrkko","executionInfo":{"status":"ok","timestamp":1719269207247,"user_tz":420,"elapsed":17,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"J1dyFBfMrkko","execution_count":5,"outputs":[]},{"cell_type":"code","source":["def calculate_option_prices(S, K, ir, vol, T):#Peyman has thoughts here\n","\n","    dt = T / (S.shape[1]-1)\n","\n","    # Convert to np.ndarray\n","    K = torch.full_like(S, K)\n","    ir = torch.full_like(S, ir)\n","    vol = torch.full_like(S, vol)\n","\n","    T = torch.full_like(S, T)\n","    t = torch.zeros_like(S)\n","    for j in range(t.shape[1]): t[:, j] = j*dt\n","    tau = T - t\n","    prices = torch.zeros_like(S)\n","\n","    # Calc prices before expiry\n","    d1 = calculate_d1(S[:, :-1], K[:, :-1], ir[:, :-1], vol[:, :-1], tau[:, :-1])\n","    d2 = calculate_d2(S[:, :-1], K[:, :-1], ir[:, :-1], vol[:, :-1], tau[:, :-1])\n","    df = np.exp(-ir[:, :-1] * tau[:, :-1])\n","    prices[:, :-1] = S[:, :-1] * stats.norm.cdf(d1) - K[:, :-1] * df * stats.norm.cdf(d2)\n","\n","    # Calc prices at expiry\n","    prices[:, -1] = torch.from_numpy(np.where(S[:, -1] > K[:, -1], S[:, -1] - K[:, -1], 0.0))\n","\n","    return prices"],"metadata":{"id":"soisnlCutRA-","executionInfo":{"status":"ok","timestamp":1719269207247,"user_tz":420,"elapsed":15,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"soisnlCutRA-","execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"w77Vx-RIsldF","executionInfo":{"status":"ok","timestamp":1719269207247,"user_tz":420,"elapsed":14,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"w77Vx-RIsldF","execution_count":6,"outputs":[]},{"cell_type":"code","source":["def delta_pnl(S,C,D,kappa,TIME,time_step,n_samples):\n","    \"\"\"Calculate the average loss for the batch\n","    S: Stock prices (BATCH_SIZE,TIME_STEP)\n","    C: Option prices (BATCH_SIZE,TIME_STEP)\n","    D: Option Deltas (BATCH_SIZE,TIME_STEP)\n","    PHI: Hedging strategy(BATCH_SIZE,TIME_STEP+1)- only PHI[:,0] used\n","    LAM: Risk aversion parameter\n","    TIME: Time horizon T\"\"\"\n","\n","\n","    PHI = torch.zeros((n_samples, time_step + 1))\n","    PHI_0=torch.ones(n_samples)*PHI_INITIAL\n","    PHI[:,0] = PHI_0.reshape((-1,))\n","\n","    PHI_dot = torch.zeros((n_samples, time_step ))\n","    delta_t = TIME/time_step\n","    pnl_mat = torch.zeros((n_samples,time_step+1))\n","    pnl_mat[:,0] = -kappa*torch.abs(torch.mul(S[:,0],D[:,0]))\n","    print(pnl_mat.shape)\n","    for i in torch.arange(1,time_step):\n","        pnl_mat[:,i] = -1*(C[:,i]-C[:,i-1])+torch.mul(D[:,i-1],(S[:,i]-S[:,i-1]))-kappa*torch.abs(S[:,i]*(D[:,i]-D[:,i-1]))\n","    pnl_mat[:,-1] = pnl_mat[:,-1]-kappa*torch.abs(S[:,-1]*D[:,-1])\n","\n","    return pnl_mat"],"metadata":{"id":"wbOwmWQlsLDB","executionInfo":{"status":"ok","timestamp":1719269207248,"user_tz":420,"elapsed":14,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"wbOwmWQlsLDB","execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"vulnerable-belize","executionInfo":{"status":"ok","timestamp":1719269207248,"user_tz":420,"elapsed":13,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"outputs":[],"source":["def Training_Loss(S,C,PHI,PHI_dot,LAM,kappa,TIME,time_step,n_samples):\n","    \"\"\"\n","    Formulate the optimization objective based on Kolm-Rietter formulation\n","    Calculate the average loss for the batch\n","    S: Stock prices (BATCH_SIZE,TIME_STEP)\n","    C: Option prices (BATCH_SIZE,TIME_STEP)\n","    PHI: Hedging strategy(BATCH_SIZE,TIME_STEP+1)\n","    LAM: Risk aversion parameter\n","    TIME: Time horizon T\"\"\"\n","    delta_t = TIME/time_step\n","    pnl_mat = torch.zeros((n_samples,time_step+1))\n","    # initial transaction cost to put on the hedge\n","    pnl_mat[:,0] = -kappa*torch.abs(torch.mul(S[:,0],PHI[:,0]))\n","    for i in torch.arange(1,time_step):\n","        pnl_mat[:,i] = -1*(C[:,i]-C[:,i-1])+PHI[:,i]*(S[:,i]-S[:,i-1])-kappa*torch.abs(S[:,i]*PHI_dot[:,i]*delta_t)\n","    #transaction cost at maturity to unwind the hedge\n","    pnl_mat[:,-1] = pnl_mat[:,-1]-kappa*S[:,-1]*(torch.abs(PHI[:,-1])+0.01*PHI[:,-1]**2)\n","    loss_mat = -1*pnl_mat+LAM/2*pnl_mat**2 #loss_mat.shape =(n_samples,time_step)\n","    return torch.mean(loss_mat), pnl_mat"],"id":"vulnerable-belize"},{"cell_type":"code","source":["criterion = nn.MSELoss() # MSE Loss"],"metadata":{"id":"c9nAsuMgsxtk","executionInfo":{"status":"ok","timestamp":1719269207248,"user_tz":420,"elapsed":12,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"c9nAsuMgsxtk","execution_count":9,"outputs":[]},{"cell_type":"code","source":["#initialization of parameters\n","def weights_init_uniform_rule(m):\n","        classname = m.__class__.__name__\n","        # for every Linear layer in a model..\n","        if classname.find('nn.Linear') != -1:\n","            # get the number of the inputs\n","            n = m.in_features\n","            y = 1.0/np.sqrt(n)\n","            m.weight.data.uniform_(-y, y)\n","            m.bias.data.fill_(0)\n","\n","### Networks\n","class Phi_Dot_0(nn.Module):\n","    def __init__(self):\n","        super(Phi_Dot_0, self).__init__()\n","        self.phi_Dot_0 = nn.Linear(1, 1)\n","    def forward(self, x):\n","        return self.phi_Dot_0(x)\n","\n","\n","class RL_Net(nn.Module):\n","    def __init__(self,INPUT_DIM,OUTPUT_DIM,HIDDEN_DIM):\n","        super(RL_Net, self).__init__()\n","        self.input_dim = INPUT_DIM\n","        self.output_dim = OUTPUT_DIM\n","        self.hidden_dim = HIDDEN_DIM\n","        current_dim = self.input_dim\n","        self.layers = nn.ModuleList()\n","        self.bn = nn.ModuleList()\n","        self.droupout = nn.ModuleList() #drop out layer for regularization\n","        for hdim in self.hidden_dim:\n","            self.layers.append(nn.Linear(int(current_dim), int(hdim)))\n","            self.bn.append(nn.BatchNorm1d(int(hdim)))\n","            self.droupout.append(nn.Dropout(0.25)) # add a dropout layer\n","            current_dim = hdim\n","        self.layers.append(nn.Linear(int(current_dim), int(self.output_dim)))\n","    def forward(self, x):\n","        for i, layer in enumerate(self.layers[:-1]):\n","            x = layer(x)\n","            x = self.bn[i](x)\n","            x = F.relu(x)\n","        out = self.layers[-1](x)\n","        return out\n"],"metadata":{"id":"6wxIq9Aessgw","executionInfo":{"status":"ok","timestamp":1719269207249,"user_tz":420,"elapsed":12,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"id":"6wxIq9Aessgw","execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"weird-reconstruction","executionInfo":{"status":"ok","timestamp":1719269207249,"user_tz":420,"elapsed":12,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"outputs":[],"source":["def TRAIN_graph(S_0,vol,mu,ir,K,PHI_INITIAL,LAM,kappa,TIME,EPOCH,n_samples,time_step,HIDDEN_DIM_Utility,LR_Utility = 0.001,saving=0,LR_Adjust=dict(),OPT_Utility=\"ADAM\",SEED_Utility1=0,SEED_Utility2=0):\n","\n","    \"\"\"\n","    n_samples: path size of the Brownian Motion\n","    time_step: discretization step\n","    LR_Utility: initial learning rate\n","    saving: list, to indicate at which epoch should have the models be saved to the path_temp\n","         saving=0 means no saving\n","    LR_Adjust: a dictoinary in which the value is the absolute DECAY,\n","          and the key is the epoch corresponding to the updated learning rate\n","    OPT_Utility: \"ADAM\" or \"SGD\"\n","    \"\"\"\n","    model_list_Utility = []\n","    i = 0\n","    while i <= time_step:\n","        model = RL_Net(INPUT_DIM_Utility,OUTPUT_DIM,HIDDEN_DIM_Utility)\n","        model.apply(weights_init_uniform_rule)\n","        model_list_Utility.append(model)\n","        i += 1\n","    if OPT_Utility==\"SGD\":\n","        optimizer_Utility = torch.optim.SGD((par for model in model_list_Utility\n","                        for par in model.parameters()),\n","                                lr=LR_Utility)\n","    if OPT_Utility==\"ADAM\":\n","        optimizer_Utility = torch.optim.Adam((par for model in model_list_Utility\n","                        for par in model.parameters()),\n","                        lr=LR_Utility, betas=(0.9, 0.99))\n","\n","    loss_arr_Utility = []\n","    PHI_0=torch.ones(n_samples)*PHI_INITIAL\n","    DUMMY_1 = torch.ones(n_samples).reshape((n_samples, 1))\n","    for epoch in tqdm(range(EPOCH)):\n","        ### tuning the learning rate\n","        if epoch in LR_Adjust.keys():\n","            DECAY = LR_Adjust[epoch]\n","            for g in optimizer_Utility.param_groups:\n","                g['lr'] = LR_Utility*DECAY\n","\n","        ### W_t: (SAMPLE_SIZE,TIME_STEP+1)\n","        W=torch.cumsum(torch.normal(0, np.sqrt(TIME*1/time_step), size=(n_samples, time_step)), dim=1) # simukate Wiener process\n","        W=torch.cat((torch.zeros((n_samples,1)),W),dim=1)\n","\n","        ### Stock process batch(SAMPLE_SIZE,TIME_STEP+1)\n","        S = calculate_stock_prices(S_0,mu,vol,W)\n","\n","        ### Calculate option prices batch (SAMPLE_SIZE,TIME_STEP+1)\n","        C = calculate_option_prices(S, K, ir, vol, TIME)\n","        ### Calculate option deltas\n","        D = calculate_deltas(S, K, ir, vol, TIME)\n","\n","        optimizer_Utility.zero_grad()\n","        PHI = torch.zeros((n_samples, time_step + 1))\n","\n","        PHI[:,0] = PHI_0.reshape((-1,))\n","\n","        PHI_dot = torch.zeros((n_samples, time_step ))\n","\n","        for t in range(time_step):#t=0,...,time_step-1, X_utility.shape =(SAMPLE_SIZE,TIME_STEP)\n","            t_tensor=t/time_step*TIME*torch.ones(n_samples).reshape(-1,1)\n","            x_Utility=torch.cat((t_tensor,S[:,t].reshape(-1,1),PHI[:,t].reshape(-1,1)),dim=1)\n","            PHI_dot[:,t] = model_list_Utility[t](x_Utility).reshape(-1,)\n","            PHI[:,(t+1)] = PHI[:,t].reshape(-1)+PHI_dot[:,(t)].reshape(-1)*TIME/time_step\n","        loss_Utility, _ = Training_Loss(S,C,PHI,PHI_dot,LAM,kappa,TIME,time_step,n_samples)\n","        loss_arr_Utility.append(loss_Utility.data)\n","        loss_Utility.backward()   #compute gradient\n","        optimizer_Utility.step()  #update NN weights\n","        if np.isinf(loss_Utility.data.cpu().numpy()) or np.isnan(loss_Utility.data.cpu().numpy()):\n","            print(\"\\nFAIL\")\n","            break\n","        ### saving\n","        path_Q = './models/'\n","        if saving:\n","            if epoch%100==0:\n","                for i,model in enumerate(model_list_Utility):\n","                      torch.save(model.state_dict(),path_Q+'Utility_para{}.pkl'.format(i))\n","                torch.save(loss_arr_Utility,path_Q+\"Utility_LOSS_arr.pt\")\n","                torch.save(optimizer_Utility.state_dict(),path_Q+\"Utility_optimizer.pt\")\n","                print(\"\\n saving models after {} Epochs\".format(epoch+1))\n","    result={\n","        'loss':loss_arr_Utility,\n","        'model_list':model_list_Utility\n","      }\n","    return(result)"],"id":"weird-reconstruction"},{"cell_type":"code","execution_count":12,"metadata":{"id":"smooth-worse","executionInfo":{"status":"ok","timestamp":1719269207249,"user_tz":420,"elapsed":10,"user":{"displayName":"Alfatti","userId":"00464344324257884815"}}},"outputs":[],"source":["S_0 =100\n","K =100\n","vol = 0.20/np.sqrt(252)\n","mu = 0.05/252\n","ir = 0\n","PHI_INITIAL = 0.0\n","LAM = 0.1\n","TIME = 30\n","EPOCH =500\n","n_samples = 50000\n","time_step = 90\n","LR_Utility = 0.01\n","INPUT_DIM_Utility = 3 #The dimension of the input is 5:(t,S_t,phi_t)\n","OUTPUT_DIM = 1\n","HIDDEN_DIM_Utility = [100,150,100]\n","kappa = 0.01"],"id":"smooth-worse"},{"cell_type":"code","source":["\n","result = TRAIN_graph(S_0,vol,mu,ir,K,PHI_INITIAL,LAM,kappa,TIME,EPOCH,n_samples,time_step,HIDDEN_DIM_Utility,LR_Utility = 0.001,saving=0,LR_Adjust=dict(),OPT_Utility=\"ADAM\",SEED_Utility1=0,SEED_Utility2=0)\n","\n","model_list_Utility = result['model_list']\n","### calulate pnl on test set\n","n_samples = 1000\n","  ### W_t: (SAMPLE_SIZE,TIME_STEP+1)\n","W=torch.cumsum(torch.normal(0, np.sqrt(TIME*1/time_step), size=(n_samples, time_step)), dim=1) # simukate Wiener process\n","W=torch.cat((torch.zeros((n_samples,1)),W),dim=1)\n","\n","### Stock process batch(SAMPLE_SIZE,TIME_STEP+1)\n","S = calculate_stock_prices(S_0,mu,vol,W)\n","\n","### Calculate option prices batch (SAMPLE_SIZE,TIME_STEP+1)\n","C = calculate_option_prices(S, K, ir, vol, TIME)\n","### Calculate option deltas\n","D = calculate_deltas(S, K, ir, vol, TIME)\n","PHI = torch.zeros((n_samples, time_step + 1))\n","PHI_0 = torch.ones(n_samples)*PHI_INITIAL\n","PHI[:,0] = PHI_0.reshape((-1,))\n","\n","PHI_dot = torch.zeros((n_samples, time_step ))\n","\n","for t in range(time_step):#t=0,...,time_step-1, X_utility.shape =(SAMPLE_SIZE,TIME_STEP)\n","    t_tensor=t/time_step*TIME*torch.ones(n_samples).reshape(-1,1)\n","    x_Utility=torch.cat((t_tensor,S[:,t].reshape(-1,1),PHI[:,t].reshape(-1,1)),dim=1)\n","    PHI_dot[:,t] = model_list_Utility[t](x_Utility).reshape(-1,)\n","    PHI[:,(t+1)] = PHI[:,t].reshape(-1)+PHI_dot[:,(t)].reshape(-1)*TIME/time_step\n","\n","_,pnl_mat = Training_Loss(S,C,PHI,PHI_dot,LAM,kappa,TIME,time_step,n_samples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9HdvRH4Moz5g","outputId":"586e1b50-9010-4a6d-b628-54917c859417"},"id":"9HdvRH4Moz5g","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/500 [00:00<?, ?it/s]"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(14,8))\n","plt.plot(result['loss'],color='black')\n","plt.xlabel('Training Epochs', fontsize=16)\n","plt.ylabel('Training Loss', fontsize=16)\n","plt.show()"],"metadata":{"id":"ahE5aFBj_OS8"},"id":"ahE5aFBj_OS8","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Out of Sample Performance"],"metadata":{"id":"Qx9IRRjKwCA8"},"id":"Qx9IRRjKwCA8"},{"cell_type":"code","source":["np.random.seed(1234)\n","torch.manual_seed(1234)\n","model_list_Utility = result['model_list']\n","n_samples =10000\n","W=torch.cumsum(torch.normal(0, np.sqrt(TIME*1/time_step), size=(n_samples, time_step)), dim=1) # simulate Wiener process\n","W=torch.cat((torch.zeros((n_samples,1)),W),dim=1)\n","### Stock process batch(SAMPLE_SIZE,TIME_STEP+1)\n","S = calculate_stock_prices(S_0,mu,vol,W)\n","\n","### Calculate option prices batch (SAMPLE_SIZE,TIME_STEP+1)\n","C = calculate_option_prices(S, K, ir, vol, TIME)\n","### Calculate option deltas\n","D = calculate_deltas(S, K, ir, vol, TIME)\n","\n","PHI = torch.zeros((n_samples, time_step + 1))\n","PHI_0=torch.ones(n_samples)*PHI_INITIAL\n","PHI[:,0] = PHI_0.reshape((-1,))\n","\n","PHI_dot = torch.zeros((n_samples, time_step ))\n","\n","for t in range(time_step):#t=0,...,time_step-1, X_utility.shape =(SAMPLE_SIZE,TIME_STEP)\n","            t_tensor=t/time_step*TIME*torch.ones(n_samples).reshape(-1,1)\n","            x_Utility=torch.cat((t_tensor,S[:,t].reshape(-1,1),PHI[:,t].reshape(-1,1)),dim=1)\n","            PHI_dot[:,t] = model_list_Utility[t](x_Utility).reshape(-1,)\n","            PHI[:,(t+1)] = PHI[:,t].reshape(-1)+PHI_dot[:,(t)].reshape(-1)*TIME/time_step\n","_, pnl_mat = Training_Loss(S,C,PHI,PHI_dot,LAM,kappa,TIME,time_step,n_samples)"],"metadata":{"id":"whqCi3HDwAol"},"id":"whqCi3HDwAol","execution_count":null,"outputs":[]},{"cell_type":"code","source":["delta_pnl_result = delta_pnl(S,C,D,kappa,TIME,time_step,n_samples)"],"metadata":{"id":"6Y1938rBwtiR"},"id":"6Y1938rBwtiR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(14,8))\n","plt.hist(-1*pnl_mat.sum(axis=1).detach().numpy(),bins=50,color = 'midnightblue',edgecolor='black',alpha =0.8,label='deep hedge')\n","plt.hist(-1*delta_pnl_result.sum(axis=1).detach().numpy(),bins=20,color = 'gold',edgecolor='black',alpha =0.8,label = 'delta hedge')\n","plt.axvline(-1*pnl_mat.sum(axis=1).detach().numpy().mean(), color='midnightblue', linestyle='dashed', linewidth=3)\n","plt.axvline(-1*delta_pnl_result.sum(axis=1).detach().numpy().mean(), color='gold', linestyle='dashed', linewidth=3)\n","\n","plt.xlabel('Total Hedge P\\&L',fontsize=16)\n"],"metadata":{"id":"sfra1WQjw-J3"},"id":"sfra1WQjw-J3","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# To-do: implement the Delta hedge with the correction term"],"metadata":{"id":"zjowSae94FJr"},"id":"zjowSae94FJr"},{"cell_type":"code","source":[],"metadata":{"id":"CkOsX2lf4KgH"},"id":"CkOsX2lf4KgH","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}